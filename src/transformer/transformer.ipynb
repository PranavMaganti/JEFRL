{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "from utils.logging import setup_logging\n",
    "\n",
    "sys.setrecursionlimit(20000)\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 3756.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"ASTBERTa/data.pkl\", \"rb\") as f:\n",
    "  data = pickle.load(f)\n",
    "\n",
    "with open(\"ASTBERTa/vocab_data.pkl\", \"rb\") as f:\n",
    "  vocab_data = pickle.load(f)\n",
    "\n",
    "token_to_id = vocab_data[\"token_to_id\"]\n",
    "id_to_token = vocab_data[\"id_to_token\"]\n",
    "special_token_ids = vocab_data[\"special_token_ids\"]\n",
    "vocab = vocab_data[\"vocab\"]\n",
    "frag_type_to_ids = vocab_data[\"frag_type_to_ids\"]\n",
    "frag_id_to_type = vocab_data[\"frag_id_to_type\"]\n",
    "\n",
    "\n",
    "for key, value in tqdm.tqdm(frag_type_to_ids.items()):\n",
    "  frag_type_to_ids[key] = torch.tensor(value, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = \"<pad>\"\n",
    "CLS_TOKEN = \"<s>\"\n",
    "SEP_TOKEN = \"</s>\"\n",
    "MASK_TOKEN = \"<mask>\"\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "special_tokens = [PAD_TOKEN, CLS_TOKEN, MASK_TOKEN, SEP_TOKEN, UNK_TOKEN]\n",
    "\n",
    "\n",
    "class FragDataset(Dataset[list[int]]):\n",
    "  def __init__(self, data: list[list[int]]):\n",
    "    self.data = data\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, index: int) -> list[int]:\n",
    "    return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 512\n",
    "MLM_PROB = 0.15\n",
    "\n",
    "def seq_data_collator(\n",
    "    batch: list[list[int]]\n",
    ") -> dict[str, torch.Tensor]:\n",
    "    seqs: list[torch.Tensor] = []\n",
    "\n",
    "    for x in batch:\n",
    "        if torch.rand(1).item() < 0.75:\n",
    "            random_start_idx = torch.randint(low = 2, high=len(x), size =(1,)).item()\n",
    "            seq = [token_to_id[CLS_TOKEN]] + x[random_start_idx:random_start_idx+MAX_SEQ_LEN-1]\n",
    "        else:\n",
    "            seq = x[:MAX_SEQ_LEN] \n",
    "        \n",
    "        assert len(seq) <= MAX_SEQ_LEN\n",
    "        seqs.append(torch.tensor(seq))\n",
    "    \n",
    "\n",
    "\n",
    "    inputs = torch.nn.utils.rnn.pad_sequence(seqs, batch_first=True)\n",
    "\n",
    "    labels = inputs.clone()\n",
    "\n",
    "    special_token_mask = torch.zeros_like(labels).float()\n",
    "    special_token_mask[(labels >= 0) & (labels <= len(special_tokens))] = 1.0\n",
    "    special_token_mask = special_token_mask.bool()\n",
    "\n",
    "    probability_matrix = torch.full(labels.shape, MLM_PROB)\n",
    "    probability_matrix.masked_fill_(special_token_mask, value=0.0)\n",
    "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "\n",
    "    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
    "    indices_replaced = (\n",
    "        torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
    "    )\n",
    "    inputs[indices_replaced] = token_to_id[MASK_TOKEN]\n",
    "    labels[~masked_indices] = -100\n",
    "\n",
    "    # 10% of the time, we replace masked input tokens with random word\n",
    "    indices_random = (\n",
    "        torch.bernoulli(torch.full(labels.shape, 0.5)).bool()\n",
    "        & masked_indices\n",
    "        & ~indices_replaced\n",
    "    )\n",
    "    random_words = torch.randint(len(vocab), labels.shape, dtype=torch.long)\n",
    "    inputs[indices_random] = random_words[indices_random]\n",
    "\n",
    "    attention_mask = torch.ones_like(inputs, dtype=torch.float)\n",
    "    attention_mask[inputs == token_to_id[PAD_TOKEN]] = 0.0\n",
    "\n",
    "    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
    "    return {\n",
    "        \"input_ids\": inputs,\n",
    "        \"labels\": labels,\n",
    "        \"attention_mask\": attention_mask,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav/.cache/pypoetry/virtualenvs/js-rl-vfj9GiAe-py3.11/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 59,313,982 trainable parameters\n",
      "RobertaForMaskedLM(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(20542, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=0)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lm_head): RobertaLMHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (decoder): Linear(in_features=768, out_features=20542, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForMaskedLM, RobertaModel, RobertaConfig\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "vocab_size = len(vocab)  # size of vocabulary\n",
    "intermediate_size = 3072  # embedding dimension\n",
    "hidden_size = 768\n",
    "\n",
    "num_hidden_layers = 6\n",
    "num_attention_heads = 12\n",
    "dropout = 0.1\n",
    "\n",
    "batch_size = 8\n",
    "top_k = 64\n",
    "\n",
    "dataset = FragDataset(data)\n",
    "train_split, val_split, test_split = random_split(dataset, [0.8, 0.1, 0.1])\n",
    "\n",
    "train_loader = DataLoader(train_split, batch_size=batch_size, shuffle=True, collate_fn=seq_data_collator)\n",
    "val_loader = DataLoader(val_split, batch_size=batch_size, shuffle=True, collate_fn=seq_data_collator)\n",
    "test_loader = DataLoader(test_split, batch_size=batch_size, shuffle=True, collate_fn=seq_data_collator)\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=vocab_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    num_attention_heads=num_attention_heads,\n",
    "    intermediate_size=intermediate_size,\n",
    "    hidden_dropout_prob=dropout,\n",
    "    max_position_embeddings=MAX_SEQ_LEN+2,\n",
    "    pad_token_id=token_to_id[PAD_TOKEN],\n",
    "    bos_token_id=token_to_id[CLS_TOKEN],\n",
    "    eos_token_id=token_to_id[SEP_TOKEN]\n",
    ")\n",
    "model = RobertaForMaskedLM(config).to(device)\n",
    "\n",
    "print(\n",
    "    f\"The model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} trainable parameters\"\n",
    ")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import tqdm\n",
    "\n",
    "MODEL_SAVE_PATH = \"ASTBERTa/models-l1/\"\n",
    "\n",
    "def evaluate_batch(model: RobertaForMaskedLM, batch: dict[str, Any]) -> torch.Tensor:\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "    out = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "    return out.loss\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model: RobertaForMaskedLM, val_loader: DataLoader[list[int]]):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(val_loader):\n",
    "            loss = evaluate_batch(model, batch)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: RobertaForMaskedLM,\n",
    "    train_loader: DataLoader[list[int]],\n",
    "    val_loader: DataLoader[list[int]],\n",
    "    optim: torch.optim.Optimizer,\n",
    "    model_save_path: Path = Path(MODEL_SAVE_PATH),\n",
    "    epochs: int = 8,\n",
    "):\n",
    "    steps = 0\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in (pbar := tqdm.trange(epochs)):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        per_batch_loss = []\n",
    "        for _, batch in (\n",
    "            ibar := tqdm.tqdm(\n",
    "                enumerate(train_loader), leave=True, total=len(train_loader)\n",
    "            )\n",
    "        ):\n",
    "            optim.zero_grad()\n",
    "            loss = evaluate_batch(model, batch)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            steps += 1\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            per_batch_loss.append(loss.item())\n",
    "            # print(f\"Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}\")\n",
    "            ibar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "            if steps % 500 == 0:\n",
    "                torch.save(model, model_save_path / f\"model_{steps}.pt\")\n",
    "\n",
    "        val_loss = evaluate(model, val_loader)\n",
    "        pbar.set_postfix(\n",
    "            {\"val_loss\": val_loss, \"train_loss\": epoch_loss / len(train_loader)}\n",
    "        )\n",
    "        print(\n",
    "            f\"Epoch: {epoch}, Val Loss: {val_loss}, Train Loss: {epoch_loss / len(train_loader)}\"\n",
    "        )\n",
    "\n",
    "        train_losses.append(per_batch_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        pickle.dump(train_losses, open(model_save_path / \"train_losses.pkl\", \"wb\"))\n",
    "        pickle.dump(val_losses, open(model_save_path / \"val_losses.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]\n",
      "  1%|          | 18/1795 [00:04<07:51,  3.77it/s, loss=6.28]\n",
      "  0%|          | 0/8 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m optim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdamW(\n\u001b[1;32m      2\u001b[0m     model\u001b[39m.\u001b[39mparameters(),\n\u001b[1;32m      3\u001b[0m     lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     betas\u001b[39m=\u001b[39m(\u001b[39m0.9\u001b[39m, \u001b[39m0.98\u001b[39m),\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m train(model, train_loader, val_loader, optim)\n",
      "Cell \u001b[0;32mIn[6], line 61\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, optim, model_save_path, epochs)\u001b[0m\n\u001b[1;32m     59\u001b[0m per_batch_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     60\u001b[0m \u001b[39m# print(f\"Epoch: {epoch}, Batch: {i}, Loss: {loss.item()}\")\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m ibar\u001b[39m.\u001b[39;49mset_postfix({\u001b[39m\"\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m\"\u001b[39;49m: loss\u001b[39m.\u001b[39;49mitem()})\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m steps \u001b[39m%\u001b[39m \u001b[39m500\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     64\u001b[0m     torch\u001b[39m.\u001b[39msave(model, model_save_path \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodel_\u001b[39m\u001b[39m{\u001b[39;00msteps\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/js-rl-vfj9GiAe-py3.11/lib/python3.11/site-packages/tqdm/std.py:1445\u001b[0m, in \u001b[0;36mtqdm.set_postfix\u001b[0;34m(self, ordered_dict, refresh, **kwargs)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostfix \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(key \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m postfix[key]\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m   1443\u001b[0m                          \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m postfix\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m   1444\u001b[0m \u001b[39mif\u001b[39;00m refresh:\n\u001b[0;32m-> 1445\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrefresh()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/js-rl-vfj9GiAe-py3.11/lib/python3.11/site-packages/tqdm/std.py:1361\u001b[0m, in \u001b[0;36mtqdm.refresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1360\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39macquire()\n\u001b[0;32m-> 1361\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdisplay()\n\u001b[1;32m   1362\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nolock:\n\u001b[1;32m   1363\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/js-rl-vfj9GiAe-py3.11/lib/python3.11/site-packages/tqdm/std.py:1509\u001b[0m, in \u001b[0;36mtqdm.display\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[39mif\u001b[39;00m pos:\n\u001b[1;32m   1508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmoveto(pos)\n\u001b[0;32m-> 1509\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__str__\u001b[39;49m() \u001b[39mif\u001b[39;49;00m msg \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m msg)\n\u001b[1;32m   1510\u001b[0m \u001b[39mif\u001b[39;00m pos:\n\u001b[1;32m   1511\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmoveto(\u001b[39m-\u001b[39mpos)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/js-rl-vfj9GiAe-py3.11/lib/python3.11/site-packages/tqdm/std.py:350\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.print_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_status\u001b[39m(s):\n\u001b[1;32m    349\u001b[0m     len_s \u001b[39m=\u001b[39m disp_len(s)\n\u001b[0;32m--> 350\u001b[0m     fp_write(\u001b[39m'\u001b[39;49m\u001b[39m\\r\u001b[39;49;00m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m s \u001b[39m+\u001b[39;49m (\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39mmax\u001b[39;49m(last_len[\u001b[39m0\u001b[39;49m] \u001b[39m-\u001b[39;49m len_s, \u001b[39m0\u001b[39;49m)))\n\u001b[1;32m    351\u001b[0m     last_len[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m len_s\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/js-rl-vfj9GiAe-py3.11/lib/python3.11/site-packages/tqdm/std.py:344\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.fp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfp_write\u001b[39m(s):\n\u001b[1;32m    343\u001b[0m     fp\u001b[39m.\u001b[39mwrite(_unicode(s))\n\u001b[0;32m--> 344\u001b[0m     fp_flush()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/js-rl-vfj9GiAe-py3.11/lib/python3.11/site-packages/tqdm/utils.py:145\u001b[0m, in \u001b[0;36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    146\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    147\u001b[0m         \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m!=\u001b[39m \u001b[39m5\u001b[39m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/js-rl-vfj9GiAe-py3.11/lib/python3.11/site-packages/ipykernel/iostream.py:497\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\u001b[39m.\u001b[39mschedule(evt\u001b[39m.\u001b[39mset)\n\u001b[1;32m    496\u001b[0m     \u001b[39m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt\u001b[39m.\u001b[39;49mwait(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mflush_timeout):\n\u001b[1;32m    498\u001b[0m         \u001b[39m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    499\u001b[0m         \u001b[39m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[1;32m    500\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIOStream.flush timed out\u001b[39m\u001b[39m\"\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39m__stderr__)\n\u001b[1;32m    501\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    623\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.11/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optim = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,\n",
    "    eps=1e-6,\n",
    "    weight_decay=0.01,\n",
    "    betas=(0.9, 0.98),\n",
    ")\n",
    "\n",
    "train(model, train_loader, val_loader, optim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "with open(\"ASTBERTa/models/sub-sequence/train_losses.pkl\", \"rb\") as f:\n",
    "    train_losses = pickle.load(f)\n",
    "  \n",
    "with open(\"ASTBERTa/models/sub-sequence/val_losses.pkl\", \"rb\") as f:\n",
    "    val_losses = pickle.load(f)\n",
    "\n",
    "train_losses = np.array(train_losses)\n",
    "val_losses = np.array(val_losses)\n",
    "\n",
    "N = train_losses.shape[0]\n",
    "\n",
    "\n",
    "sns.lineplot(x=np.arange(0, N), y=train_losses.mean(axis=1), label=\"train\")\n",
    "sns.lineplot(x=np.arange(0, N), y=val_losses, label=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_model = torch.load(\"ASTBERTa/models/final/model_28000.pt\")\n",
    "model = dp_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import esprima\n",
    "from js_ast.nodes import Node\n",
    "from js_ast.fragmentise import frag_to_str, node_to_frags, hash_frag\n",
    "\n",
    "code = \"\"\"\n",
    "function foo() {\n",
    "    var a = 1;\n",
    "    var b = 2;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "ast = esprima.parseScript(code)\n",
    "ast = Node.from_dict(ast.toDict())\n",
    "\n",
    "\n",
    "frag_seq = []\n",
    "frag_info_seq = []\n",
    "node_types = set()\n",
    "\n",
    "\n",
    "node_to_frags(ast, frag_seq, frag_info_seq, node_types)\n",
    "frags_str = [frag_to_str(frag) for frag in frag_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"('type', 'Program')('sourceType', 'script')[('type', 'FunctionDeclaration')]\", \"('type', 'FunctionDeclaration'){('type', 'Identifier')}[]('generator', False)('isAsync', False)('expression', False){('type', 'BlockStatement')}\", \"('type', 'Identifier')('name', 'foo')\", \"('type', 'BlockStatement')[('type', 'VariableDeclaration'),('type', 'VariableDeclaration')]\", \"('type', 'VariableDeclaration')[('type', 'VariableDeclarator')]('kind', 'var')\", \"('type', 'VariableDeclarator'){('type', 'Identifier')}{('type', 'Literal')}\", \"('type', 'Identifier')('name', 'a')\", \"('type', 'Literal')('value', 1)('raw', '1')('regex', None)('bigint', None)\", \"('type', 'VariableDeclaration')[('type', 'VariableDeclarator')]('kind', 'var')\", \"('type', 'VariableDeclarator'){('type', 'Identifier')}{('type', 'Literal')}\", \"('type', 'Identifier')('name', 'b')\", \"('type', 'Literal')('value', 2)('raw', '2')('regex', None)('bigint', None)\"]\n"
     ]
    }
   ],
   "source": [
    "print(frags_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16992\n",
      "tensor([[    1,  8312, 10449,  9308,     2,  3305,  5516, 11618, 11153,  3305,\n",
      "          5516,  1327,  8643,     3]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "frag_seq_ids = [token_to_id[hash_frag(frag)] for frag in frag_seq]\n",
    "frag_seq_ids = [token_to_id[CLS_TOKEN]] + frag_seq_ids + [token_to_id[SEP_TOKEN]]\n",
    "k = 4\n",
    "print(frag_seq_ids[k])\n",
    "frag_seq_ids[k] = token_to_id[MASK_TOKEN]\n",
    "\n",
    "frag_seq_ids = torch.tensor(frag_seq_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "print(frag_seq_ids)\n",
    "\n",
    "out = model(frag_seq_ids).logits\n",
    "preds = nn.functional.softmax(out, dim=-1)\n",
    "pred = torch.argmax(preds, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1294,  8312, 10449,  8698,  4659,  3305,  5516, 11618, 11153,  3305,\n",
      "          5516,  1327,  8643,    12]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [\n",
    "    [1, 2, 5, 6, 0, 0],\n",
    "    [2, 3, 5, 0, 0, 0],\n",
    "    [1, 2, 3, 4, 5, 6],\n",
    "]\n",
    "\n",
    "# t = \n",
    "# print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig(\n",
    "    vocab_size=vocab_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    num_attention_heads=num_attention_heads,\n",
    "    intermediate_size=intermediate_size,\n",
    "    hidden_dropout_prob=dropout,\n",
    "    max_position_embeddings=1026,\n",
    ")\n",
    "ast_net = RobertaModel(config).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 6.1722e-01,  4.3260e-01,  1.5933e-01,  ...,  7.3708e-01,\n",
       "           4.6374e-01,  1.1797e-01],\n",
       "         [ 8.8787e-01,  8.1163e-01,  1.0322e+00,  ...,  3.8541e-01,\n",
       "           3.7509e-02, -1.1324e+00],\n",
       "         [ 2.2646e-01, -1.1131e+00,  1.8539e-01,  ...,  8.4913e-01,\n",
       "           1.5349e-01, -5.2603e-01],\n",
       "         [ 6.2816e-01,  6.4152e-01, -8.3964e-01,  ...,  3.9646e-01,\n",
       "           5.3345e-01,  1.8185e-01],\n",
       "         [ 7.1551e-01,  4.8978e-01,  1.2540e+00,  ...,  3.0588e-01,\n",
       "          -1.2160e-02, -4.7937e-01],\n",
       "         [ 6.9145e-01,  2.3819e-01, -2.1357e-01,  ..., -7.7907e-02,\n",
       "           4.3772e-01, -1.0086e+00]],\n",
       "\n",
       "        [[ 6.8574e-01,  4.0473e-01,  5.9456e-01,  ...,  3.3835e-01,\n",
       "           1.0181e-03, -1.3227e-01],\n",
       "         [ 2.3013e+00, -1.9017e-02,  1.4823e+00,  ...,  1.9135e-01,\n",
       "           6.0835e-01,  5.7279e-01],\n",
       "         [-5.1198e-01,  7.0884e-01,  6.3066e-01,  ...,  1.8414e-01,\n",
       "          -1.3327e+00, -4.8723e-01],\n",
       "         [ 1.1590e+00,  8.3474e-01,  9.0665e-01,  ...,  6.6811e-01,\n",
       "           3.2725e-01, -2.6330e-01],\n",
       "         [ 8.6665e-01,  1.1094e+00, -2.8083e-02,  ..., -3.4626e-01,\n",
       "           4.4667e-01, -5.0717e-01],\n",
       "         [ 1.6190e+00,  2.4067e-01,  1.2138e+00,  ...,  2.0715e-02,\n",
       "           6.4963e-02, -1.0664e+00]],\n",
       "\n",
       "        [[ 6.7585e-01,  2.0647e-01, -3.1908e-01,  ...,  1.3352e+00,\n",
       "           1.0959e+00,  4.2528e-01],\n",
       "         [ 5.4652e-01, -3.5496e-01,  1.2827e+00,  ...,  9.7265e-01,\n",
       "          -2.7103e-01, -1.5929e+00],\n",
       "         [ 3.5243e-01,  2.8967e-02,  6.0772e-01,  ...,  9.8200e-01,\n",
       "           1.0623e+00,  6.1537e-01],\n",
       "         [ 2.3226e-01,  9.0680e-01,  7.2346e-01,  ..., -1.0187e-01,\n",
       "          -6.4288e-01,  3.8581e-01],\n",
       "         [-3.1504e-02,  5.1294e-01, -1.1442e-01,  ...,  8.4977e-01,\n",
       "           6.9422e-01, -9.5980e-01],\n",
       "         [ 1.3337e-01,  5.3790e-01, -5.2934e-01,  ..., -1.2586e-01,\n",
       "          -1.3022e-01, -1.0677e+00]]], device='cuda:0',\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.0369, -0.2100,  0.2814,  ...,  0.3352,  0.1203,  0.1896],\n",
       "        [ 0.5358, -0.2305, -0.4065,  ...,  0.3152,  0.1431,  0.6030],\n",
       "        [ 0.2671, -0.5286,  0.2310,  ...,  0.1255,  0.3267, -0.0773]],\n",
       "       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast_net(input_ids=torch.tensor(t, dtype=torch.long).to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "js-rl-vfj9GiAe-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
