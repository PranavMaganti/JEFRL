{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav/.cache/pypoetry/virtualenvs/js-rl-vfj9GiAe-py3.10/lib/python3.11/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Initial coverage: 14.73665% Final coverage: 14.78238%\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from optimum.bettertransformer import BetterTransformer\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import RobertaConfig, RobertaForMaskedLM\n",
    "\n",
    "from rl.dqn import DQN, ReplayMemory\n",
    "from rl.env import FuzzingEnv\n",
    "from rl.fuzzing_action import FuzzingAction\n",
    "from rl.tokenizer import ASTTokenizer\n",
    "from utils.logging import setup_logging\n",
    "\n",
    "sys.setrecursionlimit(20000)\n",
    "setup_logging()\n",
    "MAX_FRAGMENT_SEQ_LEN = 512  # Maximum length of the AST fragment sequence\n",
    "\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "CLS_TOKEN = \"<s>\"\n",
    "SEP_TOKEN = \"</s>\"\n",
    "MASK_TOKEN = \"<mask>\"\n",
    "UNK_TOKEN = \"<unk>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranav/.cache/pypoetry/virtualenvs/js-rl-vfj9GiAe-py3.10/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3505: FutureWarning: Possible set difference at position 2\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/pranav/.cache/pypoetry/virtualenvs/js-rl-vfj9GiAe-py3.10/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3505: FutureWarning: Possible nested set at position 2\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/pranav/.cache/pypoetry/virtualenvs/js-rl-vfj9GiAe-py3.10/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3505: FutureWarning: Possible nested set at position 1\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "with open(\"../ASTBERTa/frag_data.pkl\", \"rb\") as f:\n",
    "    frag_data = pickle.load(f)\n",
    "\n",
    "with open(\"../ASTBERTa/vocab_data.pkl\", \"rb\") as f:\n",
    "    vocab_data = pickle.load(f)\n",
    "\n",
    "\n",
    "frag_seqs = frag_data[\"frag_seqs\"]\n",
    "frag_id_to_type = frag_data[\"frag_id_to_type\"]\n",
    "frag_id_to_frag = frag_data[\"frag_id_to_frag\"]\n",
    "frag_type_to_id = frag_data[\"frag_type_to_id\"]\n",
    "\n",
    "vocab = vocab_data[\"vocab\"]\n",
    "token_to_id = vocab_data[\"token_to_id\"]\n",
    "id_to_token = vocab_data[\"id_to_token\"]\n",
    "special_token_ids = vocab_data[\"special_token_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vocab_size = len(vocab)  # size of vocabulary\n",
    "intermediate_size = 3072  # embedding dimension\n",
    "hidden_size = 768\n",
    "\n",
    "num_hidden_layers = 6\n",
    "num_attention_heads = 12\n",
    "dropout = 0.1\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=vocab_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    num_attention_heads=num_attention_heads,\n",
    "    intermediate_size=intermediate_size,\n",
    "    hidden_dropout_prob=dropout,\n",
    "    max_position_embeddings=MAX_FRAGMENT_SEQ_LEN + 2,\n",
    ")\n",
    "\n",
    "\n",
    "# Load the ASTBERTa model\n",
    "tokenizer = ASTTokenizer(vocab, token_to_id, MAX_FRAGMENT_SEQ_LEN, device)\n",
    "pretrained_model = torch.load(\"../ASTBERTa/models/final/model_27500.pt\")\n",
    "\n",
    "if isinstance(pretrained_model, torch.nn.DataParallel):\n",
    "    pretrained_model = pretrained_model.module\n",
    "\n",
    "ast_net = RobertaForMaskedLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=None,\n",
    "    state_dict=pretrained_model.state_dict(),\n",
    "    config=config,\n",
    ").to(device)\n",
    "ast_net = BetterTransformer.transform(ast_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from js_ast.fragmentise import hash_frag\n",
    "\n",
    "\n",
    "def tokenize(frag_seq):\n",
    "    frag_id_seq: list[int] = []\n",
    "    frag_id_seq.append(token_to_id[CLS_TOKEN])\n",
    "\n",
    "    for frag in frag_seq:\n",
    "        frag_hash = hash_frag(frag)\n",
    "        if frag_hash in token_to_id:\n",
    "            frag_id_seq.append(token_to_id[frag_hash])\n",
    "        else:\n",
    "            oov_frag: dict[str, str] = {\"type\": frag[\"type\"]}\n",
    "            oov_frag_hash = hash_frag(oov_frag)\n",
    "            if oov_frag_hash in token_to_id:\n",
    "                frag_id_seq.append(token_to_id[oov_frag_hash])\n",
    "            else:\n",
    "                print(f\"UNK_TOKEN: {frag_hash}\")\n",
    "                frag_id_seq.append(token_to_id[UNK_TOKEN])\n",
    "        \n",
    "        if len(frag_id_seq) >= MAX_FRAGMENT_SEQ_LEN:\n",
    "            break\n",
    "\n",
    "    if len(frag_id_seq) < MAX_FRAGMENT_SEQ_LEN:\n",
    "        frag_id_seq.append(token_to_id[SEP_TOKEN])\n",
    "\n",
    "    return torch.tensor(frag_id_seq, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14017/14017 [01:07<00:00, 207.49it/s]\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "\n",
    "for seq in tqdm.tqdm(frag_seqs):\n",
    "    tokenized = tokenize(seq)\n",
    "    mask_idxs = torch.randint(1, len(tokenized) - 1, (max(1, int(len(tokenized) * 0.1)),))\n",
    "    masked_frag_types = [frag_id_to_type[frag_id.item()] for frag_id in tokenized[mask_idxs]]\n",
    "\n",
    "    tokenized[mask_idxs] = token_to_id[MASK_TOKEN]\n",
    "    inputs = tokenizer.pad_batch([tokenized])\n",
    "    out = ast_net(**inputs)\n",
    "\n",
    "    preds = out.logits.argmax(dim=-1).detach().cpu()[0]\n",
    "    masked_preds = preds[mask_idxs]\n",
    "    out_frag_types = [frag_id_to_type[frag_id.item()] for frag_id in masked_preds]\n",
    "\n",
    "    correct = [a == b for a, b in zip(masked_frag_types, out_frag_types)]\n",
    "    acc.append(sum(correct) / len(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9211684989041612\n"
     ]
    }
   ],
   "source": [
    "print(sum(acc) / len(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "js-rl-vfj9GiAe-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
