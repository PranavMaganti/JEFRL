{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from rl.fuzzing_action import FuzzingAction\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_names = [\n",
    "    # \"2023-06-17T13:28:.471488_baseline\",\n",
    "    # \"2023-06-16T23:18:.282375_baseline\",\n",
    "    # \"2023-06-20T06:37:.270395_baseline\",\n",
    "    # \"2023-06-20T02:21:.152992_baseline\",\n",
    "    # \"2023-06-20T22:43:.174807_baseline\",\n",
    "    # \"2023-06-21T03:39:.120400_baseline\",\n",
    "    # \"2023-06-19T14:00:.768497\",\n",
    "    \"2023-06-19T14:48:.793014\",\n",
    "    # \"2023-06-19T22:16:.955213\",\n",
    "    # \"2023-06-19T22:58:.025511\",\n",
    "    # \"2023-06-18T14:11:.410515\",\n",
    "    # \"2023-06-18T14:11:.664869\",\n",
    "    # \"2023-06-18T22:20:.078248\",\n",
    "    # \"2023-06-19T03:30:.985346\",\n",
    "    # \"2023-06-17T18:20:.073534\",\n",
    "    # \"2023-06-20T16:33:.711809\",\n",
    "    # \"2023-06-20T16:38:.514775\"\n",
    "    # \"2023-06-21T04:52:.430666\",\n",
    "    # \"2023-06-19T22:16:.955213\",\n",
    "    # \"2023-06-21T00:57:.789686\"\n",
    "]\n",
    "# smart_folder_name = \"2023-06-15T12:38:.323908\"\n",
    "# smart_interesting_folder = Path(f\"../corpus/interesting/{smart_folder_name}\")\n",
    "data_labels = [\n",
    "    # \"Baseline 1\",\n",
    "    # \"Baseline 1\",\n",
    "    # \"Baseline 2\",\n",
    "    # \"Baseline 3\",\n",
    "    # \"Baseline 4\",\n",
    "    # \"Random\",\n",
    "    \"Final 1\",\n",
    "    \"Final 2\",\n",
    "    \"Final 3\",\n",
    "    # \"Non-Pretrained\",\n",
    "    # \"Pretrained\"\n",
    "    # \"Smart (Small Replay)\",\n",
    "    # \"Smart (Big Replay)\",\n",
    "    # \"Replay memory: 75000\",\n",
    "    # \"Replay memory: 100000\",\n",
    "    # \"Small LR\",\n",
    "    # \"Big LR\",\n",
    "    # \"1\",\n",
    "    # \"2\"\n",
    "]\n",
    "\n",
    "data_folders = [Path(f\"../data/{name}\") for name in data_folder_names]\n",
    "\n",
    "# smart_files = list(smart_folder.rglob(\"*.pkl\"))\n",
    "# baseline_files = list(baseline_folder.rglob(\"*.pkl\"))\n",
    "\n",
    "step_re = r\"run_data_(\\d+).pkl\"\n",
    "\n",
    "latest_steps = []\n",
    "for folder in data_folders:\n",
    "    files = list(folder.rglob(\"*.pkl\"))\n",
    "    run_data_file = max(files, key=lambda x: x.stat().st_mtime)\n",
    "    step = int(re.match(step_re, run_data_file.name).group(1))\n",
    "    latest_steps.append(step)\n",
    "\n",
    "latest_step = min(latest_steps)\n",
    "\n",
    "\n",
    "num_baselines = 3\n",
    "\n",
    "for i in range(num_baselines):\n",
    "    latest_steps[i] = min(latest_steps[i], max(latest_steps[num_baselines:]))\n",
    "\n",
    "print(latest_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_data = []\n",
    "\n",
    "for folder, step in zip(data_folders, latest_steps):\n",
    "    with open(folder / f\"run_data_{step}.pkl\", \"rb\") as f:\n",
    "        run_data.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run_data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Average optimization time:\", np.mean(run_data[0][\"optimization_times\"]))\n",
    "# print(\"Average action time:\", np.mean(run_data[0][\"action_times\"]))\n",
    "# print(\"Average execution time:\", np.mean(run_data[0][\"exec_times\"]))\n",
    "# print(\"Average code generation time:\", np.mean(run_data[0][\"code_gen_times\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(20, 14))\n",
    "\n",
    "# sns.lineplot(x=np.arange(len(run_data[0][\"optimization_times\"])), y=run_data[0][\"optimization_times\"], ax=ax[0, 0])\n",
    "# sns.lineplot(x=np.arange(len(run_data[0][\"action_times\"])), y=run_data[0][\"action_times\"],  ax=ax[0, 1])\n",
    "# sns.lineplot(x=np.arange(len(run_data[0][\"exec_times\"])), y=run_data[0][\"exec_times\"],  ax=ax[1, 0])\n",
    "# sns.lineplot(x=np.arange(len(run_data[0][\"code_gen_times\"])), y=run_data[0][\"code_gen_times\"], ax=ax[1, 1])\n",
    "\n",
    "# ax[0, 0].set_title(\"Optimization\")\n",
    "# ax[0, 1].set_title(\"Action\")\n",
    "# ax[1, 0].set_title(\"Execution\")\n",
    "# ax[1, 1].set_title(\"Code Generation\")\n",
    "\n",
    "# ax[0, 0].set_xlabel(\"Step\")\n",
    "# ax[0, 1].set_xlabel(\"Step\")\n",
    "# ax[1, 0].set_xlabel(\"Number of executions\")\n",
    "# ax[1, 1].set_xlabel(\"Number of code generations\")\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# sns.lineplot(x=np.arange(len(run_data[0][\"optimization_times\"])), y=run_data[0][\"optimization_times\"], label=\"Optimization\")\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# sns.lineplot(x=np.arange(len(run_data[0][\"action_times\"])), y=run_data[0][\"action_times\"], label=\"Action\")\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# sns.lineplot(x=np.arange(len(run_data[0][\"exec_times\"])), y=run_data[0][\"exec_times\"], label=\"Execution\")\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# sns.lineplot(x=np.arange(len(run_data[0][\"code_gen_times\"])), y=run_data[0][\"code_gen_times\"], label=\"Code Generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_coverage_data = []\n",
    "\n",
    "# for folder, final_step in zip([data_folders[0], data_folders[1]], latest_steps):\n",
    "#     time_coverage = []\n",
    "\n",
    "#     for step in range(1000, final_step + 1, 1000):\n",
    "#         print(step)\n",
    "#         with open(folder / f\"run_data_{step}.pkl\", \"rb\") as f:\n",
    "#             step_run_data = pickle.load(f)\n",
    "\n",
    "#         time_coverage.append((int(step_run_data[\"running_time\"].seconds/60), step_run_data[\"current_coverage\"]))\n",
    "#     time_coverage_data.append(time_coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# sns.lineplot(\n",
    "#     x=[x[0] for x in time_coverage_data[0]],\n",
    "#     y=[x[1] for x in time_coverage_data[0]],\n",
    "#     label=data_labels[0],\n",
    "# )\n",
    "# sns.lineplot(\n",
    "#     x=[x[0] for x in time_coverage_data[1]],\n",
    "#     y=[x[1] for x in time_coverage_data[1]],\n",
    "#     label=data_labels[1],\n",
    "# )\n",
    "\n",
    "# plt.xlabel(\"Time (minutes)\")\n",
    "# plt.ylabel(\"Coverage (%)\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_rewards = [[sum(episode) for episode in r[\"episode_rewards\"]] for r in run_data]\n",
    "episode_lengths = [[len(episode) for episode in r[\"episode_actions\"]] for r in run_data]\n",
    "\n",
    "df_data = {\n",
    "    \"Label\": data_labels,\n",
    "    \"Running time\": [data[\"running_time\"] for data in run_data],\n",
    "    \"Total steps\": [data[\"total_steps\"] for data in run_data],\n",
    "    \"Total executions\": [data[\"total_executions\"] for data in run_data],\n",
    "    \"Final coverage\": [f\"{data['current_coverage']:.5%}\" for data in run_data],\n",
    "    \"Number of episodes\": [len(data[\"episode_rewards\"]) for data in run_data],\n",
    "    \"Average episode reward\": [f\"{np.mean(rewards):.2f}\" for rewards in summed_rewards],\n",
    "    \"Average episode length\": [\n",
    "        f\"{np.mean(lengths):.2f}\" for lengths in episode_lengths\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(df_data)\n",
    "df = pd.DataFrame(df_data)\n",
    "\n",
    "display(df)\n",
    "# print(\"Labels: \" + \", \".join(data_labels))\n",
    "# print(\"Running times: \" + \", \".join())\n",
    "# print(\"Total steps: \" + \", \".join([str(data[\"total_steps\"]) for data in run_data]))\n",
    "# print(\"Total executions: \" + \", \".join([str(data[\"total_executions\"]) for data in run_data]))\n",
    "# print(\"Final coverage: \" + \", \".join([f\"{data['current_coverage']:.5%}\" for data in run_data]))\n",
    "# print(\"Number of episodes: \" + \", \".join([str(len(data[\"episode_rewards\"])) for data in run_data]))\n",
    "# print(f\"Average episode reward: \"+ \", \".join([f\"{np.mean(rewards):.2f}\" for rewards in summed_rewards]))\n",
    "# print(\"Average episode length: \" + \", \".join([f\"{np.mean(lengths):.2f}\" for lengths in episode_lengths]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execs = []\n",
    "actions = []\n",
    "coverages = []\n",
    "\n",
    "for data in run_data:\n",
    "    run_execs = []\n",
    "    run_actions = []\n",
    "    run_coverage = []\n",
    "\n",
    "    for (execution, num_actions), coverage in data[\"execution_coverage\"].items():\n",
    "        run_execs.append(execution)\n",
    "        run_actions.append(num_actions)\n",
    "        run_coverage.append(coverage * 100)\n",
    "\n",
    "    execs.append(run_execs)\n",
    "    actions.append(run_actions)\n",
    "    coverages.append(run_coverage)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of Engine Executions\")\n",
    "plt.ylabel(\"Coverage (%)\")\n",
    "# plt.title(\"Coverage vs. Number of JavaScript Engine Executions\")\n",
    "\n",
    "for i, label in enumerate(data_labels):\n",
    "    sns.lineplot(x=execs[i], y=coverages[i], label=label)\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.xlabel(\"Number of Actions\")\n",
    "plt.ylabel(\"Coverage (%)\")\n",
    "# plt.title(\"Coverage vs. Total Number of Actions\")\n",
    "\n",
    "episodes = min([len(data[\"episode_rewards\"]) for data in run_data[num_baselines:]])\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(14, 5))\n",
    "ax[0].set_xlabel(\"Number of Actions\")\n",
    "ax[0].set_ylabel(\"Coverage (%)\")\n",
    "\n",
    "ax[1].set_xlabel(\"Episode number\")\n",
    "ax[1].set_ylabel(\"Episode Reward\")\n",
    "\n",
    "\n",
    "for i, label in enumerate(data_labels):\n",
    "    sns.lineplot(x=actions[i], y=coverages[i], label=label, ax=ax[0])\n",
    "    sns.lineplot(\n",
    "        x=np.arange(len(summed_rewards[i]))[:episodes:6],\n",
    "        y=summed_rewards[i][:episodes:6],\n",
    "        label=label,\n",
    "        ax=ax[1],\n",
    "    )\n",
    "\n",
    "ax[1].set_ylim(-100, 100)\n",
    "ax[1].axhline(y=0, color=\"r\", linestyle=\"-\")\n",
    "\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_1 = np.mean(np.array(coverages[0:3]), axis=0).squeeze()\n",
    "std_1 = np.std(np.array(coverages[0:3]), axis=0).squeeze()\n",
    "mean_2 = np.mean(np.array(coverages[3:5]), axis=0).squeeze()\n",
    "std_2 = np.std(np.array(coverages[3:5]), axis=0).squeeze()\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(14, 5))\n",
    "\n",
    "\n",
    "axs[0].plot(actions[0], mean_1, \"b-\", label=\"Random\")\n",
    "axs[0].fill_between(actions[0], mean_1 - std_1, mean_1 + std_1, color=\"b\", alpha=0.2)\n",
    "axs[0].plot(actions[0], mean_2, \"r--\", label=\"DDQN\")\n",
    "axs[0].fill_between(actions[0], mean_2 - std_2, mean_2 + std_2, color=\"r\", alpha=0.2)\n",
    "\n",
    "axs[0].legend(title=\"Agent Type\")\n",
    "\n",
    "# plt.title('Coverage vs. Total Number of Steps')\n",
    "axs[0].set_xlabel(\"Number of Steps\")\n",
    "axs[0].set_ylabel(\"Coverage (%)\")\n",
    "# ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "axs[0].tick_params(axis=\"both\", which=\"major\", labelsize=9)\n",
    "\n",
    "axs[1].plot(\n",
    "    np.arange(len(summed_rewards[0]))[:episodes:5],\n",
    "    summed_rewards[0][:episodes:5],\n",
    "    \"b-\",\n",
    "    label=\"Random\",\n",
    ")\n",
    "axs[1].plot(\n",
    "    np.arange(len(summed_rewards[3]))[:episodes:5],\n",
    "    summed_rewards[3][:episodes:5],\n",
    "    \"r-\",\n",
    "    label=\"DDQN\",\n",
    ")\n",
    "\n",
    "axs[1].set_ylim(-100, 100)\n",
    "axs[1].axhline(y=0, color=\"r\", linestyle=\"-\")\n",
    "axs[1].legend(title=\"Agent Type\")\n",
    "\n",
    "# plt.title('Coverage vs. Total Number of Steps')\n",
    "axs[1].set_xlabel(\"Episode Number\")\n",
    "axs[1].set_ylabel(\"Episode Reward\")\n",
    "# ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "axs[1].tick_params(axis=\"both\", which=\"major\", labelsize=9)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (mean_2[-1] - corpus[\"total_coverage\"].coverage() * 100)/(mean_1[-1] - corpus[\"total_coverage\"].coverage() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus[\"total_coverage\"].coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(data_labels):\n",
    "    if \"losses\" in run_data[i]:\n",
    "        plt.figure()\n",
    "        ax = sns.lineplot(\n",
    "            x=np.arange(len(run_data[i][\"losses\"])),\n",
    "            y=run_data[i][\"losses\"],\n",
    "        )\n",
    "        ax.set(xlabel=\"Steps\", ylabel=\"Loss\", title=f\"Loss vs. Episode ({label})\")\n",
    "        # ax.set_ylim(bottom=0, top=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for action in FuzzingAction:\n",
    "#     smart_episode_actions_by_type = [\n",
    "#         x[1] for x in smart_episode_actions if x[0] == action\n",
    "#     ]\n",
    "#     baseline_episode_actions_by_type = [\n",
    "#         x[1] for x in baseline_episode_actions if x[0] == action\n",
    "#     ]\n",
    "\n",
    "#     smart_action_node_type_counts = Counter(smart_episode_actions_by_type)\n",
    "#     baseline_action_node_type_counts = Counter(baseline_episode_actions_by_type)\n",
    "\n",
    "#     smart_action_node_type_counts = pd.DataFrame(\n",
    "#         smart_action_node_type_counts.items(), columns=[\"node_type\", \"count\"]\n",
    "#     )\n",
    "#     baseline_action_node_type_counts = pd.DataFrame(\n",
    "#         baseline_action_node_type_counts.items(), columns=[\"node_type\", \"count\"]\n",
    "#     )\n",
    "\n",
    "#     # Plot the distribution of actions by node type using seaborn\n",
    "#     plt.figure(figsize=(15, 5))\n",
    "#     ax = sns.barplot(x=\"node_type\", y=\"count\", data=smart_action_node_type_counts)\n",
    "#     ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "#     ax.set(xlabel=\"Node Type\", ylabel=\"Count\")\n",
    "#     plt.title(f\"Smart Fuzzing Action Distribution for {action}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_fig, action_axs = plt.subplots(\n",
    "    ncols=len(data_labels), figsize=(8, 5), sharex=True\n",
    ")\n",
    "# action_fig.suptitle(\"Action Distribution\")\n",
    "\n",
    "node_type_fig, node_tyes_axs = plt.subplots(nrows=len(data_labels), figsize=(15, 10))\n",
    "# node_type_fig.suptitle(\"Node Type Distribution\")\n",
    "\n",
    "for i, label in enumerate(data_labels):\n",
    "    episode_actions = [\n",
    "        item for sublist in run_data[i][\"episode_actions\"] for item in sublist\n",
    "    ]\n",
    "    ep_actions, node_types = zip(*episode_actions)\n",
    "    action_counts = Counter(ep_actions[-100000:])\n",
    "    node_type_counts = Counter(node_types[-100000:])\n",
    "\n",
    "    new_node_type_counts = {}\n",
    "\n",
    "    for node_type, count in node_type_counts.items():\n",
    "        if count > 100:\n",
    "            new_node_type_counts[node_type] = count\n",
    "\n",
    "    node_type_counts = new_node_type_counts\n",
    "\n",
    "    action_counts = pd.DataFrame.from_dict(action_counts, orient=\"index\")\n",
    "    action_counts[\"name\"] = [str(FuzzingAction(i)) for i in action_counts.index]\n",
    "    action_counts = action_counts.sort_values(by=\"name\", ascending=False)\n",
    "\n",
    "    print(action_counts)\n",
    "    print(node_type_counts)\n",
    "\n",
    "    node_type_counts = pd.DataFrame.from_dict(node_type_counts, orient=\"index\")\n",
    "    node_type_counts[\"name\"] = node_type_counts.index\n",
    "\n",
    "    node_type_counts = node_type_counts.sort_values(by=0, ascending=False)\n",
    "\n",
    "    sns.barplot(x=\"name\", y=0, data=action_counts, ax=action_axs)\n",
    "\n",
    "    action_axs.set(xlabel=\"Action\", ylabel=\"Count\")\n",
    "    action_axs.set_xticklabels(action_axs.get_xticklabels(), rotation=45)\n",
    "\n",
    "    # plt.legend([], [], frameon=False)\n",
    "\n",
    "    sns.barplot(x=\"name\", y=0, data=node_type_counts, ax=node_tyes_axs)\n",
    "\n",
    "    node_tyes_axs.set(xlabel=\"Node Type\", ylabel=\"Count\")\n",
    "    node_tyes_axs.set_xticklabels(\n",
    "        node_tyes_axs.get_xticklabels(), rotation=90, fontsize=12\n",
    "    )\n",
    "    # plt.legend([], [], frameon=False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_actions = [\n",
    "    item for sublist in run_data[0][\"episode_actions\"] for item in sublist\n",
    "]\n",
    "expression_counts = Counter(episode_actions[-100000:])\n",
    "\n",
    "for (action, node_type), count in expression_counts.items():\n",
    "    if node_type == \"ForStatement\":\n",
    "        print(action, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_action_fig, failed_action_axs = plt.subplots(\n",
    "    ncols=len(data_labels), figsize=(20, 5)\n",
    ")\n",
    "failed_action_fig.suptitle(\"Failed Actions by Type\")\n",
    "\n",
    "for i, label in enumerate(data_labels):\n",
    "    failed_action_counts = Counter(map(lambda x: x[0], run_data[i][\"failed_actions\"]))\n",
    "    failed_action_counts = pd.DataFrame(\n",
    "        failed_action_counts.items(), columns=[\"action_id\", \"count\"]\n",
    "    )\n",
    "    failed_action_counts[\"name\"] = [\n",
    "        str(FuzzingAction(i)) for i in failed_action_counts[\"action_id\"]\n",
    "    ]\n",
    "    failed_action_counts = failed_action_counts.sort_values(by=\"name\", ascending=False)\n",
    "    sns.barplot(\n",
    "        x=\"name\",\n",
    "        y=\"count\",\n",
    "        data=failed_action_counts,\n",
    "        ax=failed_action_axs[i],\n",
    "    )\n",
    "    failed_action_axs[i].set(xlabel=\"Action\", ylabel=\"Count\", title=f\"{label}\")\n",
    "    failed_action_axs[i].set_xticklabels(\n",
    "        failed_action_axs[i].get_xticklabels(), rotation=45\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/js-rl/corpus-8.5.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data[\"corpus\"]\n",
    "subtrees = data[\"subtrees\"]\n",
    "total_coverage = data[\"total_coverage\"]\n",
    "\n",
    "file_to_node = {state.program.origin_file: state for state in corpus}\n",
    "\n",
    "print(file_to_node)\n",
    "\n",
    "smart_interesting_folder = Path(\"../corpus/interesting/2023-06-19T14:48:.793014\")\n",
    "program_state_files = smart_interesting_folder.rglob(\"*.ps\")\n",
    "program_states = {file: pickle.load(open(file, \"rb\")) for file in program_state_files}\n",
    "\n",
    "import difflib\n",
    "import tqdm\n",
    "\n",
    "for file, state in tqdm.tqdm(program_states.items()):\n",
    "    new_program = state.generate_program_code()\n",
    "    if new_program is None:\n",
    "        print(f\"File {file} failed to generate program code\")\n",
    "        continue\n",
    "\n",
    "    if state.program.origin_file not in file_to_node:\n",
    "        print(f\"File {state.program.origin_file} not found\")\n",
    "        continue\n",
    "\n",
    "    old_program = file_to_node[state.program.origin_file].generate_program_code()\n",
    "\n",
    "    old_program = \"\\n\".join([\"--- Original File ---\", old_program])\n",
    "    new_program = \"\\n\".join([\"+++ Modified File +++\", new_program])\n",
    "\n",
    "    diff_generator = difflib.unified_diff(\n",
    "        old_program.splitlines(keepends=True),\n",
    "        new_program.splitlines(keepends=True),\n",
    "    )\n",
    "\n",
    "    # Write the diff to the output file\n",
    "    with open(file.with_suffix(\".diff\"), \"w\") as f:\n",
    "        f.writelines(diff_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.js_engine import V8Engine\n",
    "# import pickle\n",
    "\n",
    "# with open(\"../data/js-rl/corpus-8.5.pkl\", \"rb\") as f:\n",
    "#     corpus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = corpus[\"corpus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depths = []\n",
    "# for ps in corpus:\n",
    "#     ast = ps.program\n",
    "\n",
    "#     max_depth = 0\n",
    "\n",
    "#     queue = [(ast, 0)]\n",
    "\n",
    "#     while queue:\n",
    "#         node, depth = queue.pop(0)\n",
    "#         if depth > max_depth:\n",
    "#             max_depth = depth\n",
    "\n",
    "#         for child in node.children():\n",
    "#             queue.append((child, depth + 1))\n",
    "\n",
    "#     depths.append(max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sum(depths) / len(depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tqdm\n",
    "# from pathlib import Path\n",
    "\n",
    "# corpus = data[\"corpus\"]\n",
    "# subtrees = data[\"subtrees\"]\n",
    "# total_coverage = data[\"total_coverage\"]\n",
    "\n",
    "# engine = V8Engine(base_path=Path(\"../\"), version=\"8.5\")\n",
    "\n",
    "# fuzzilli_path = Path(\"../corpus/interesting/fuzzilli-2\")\n",
    "# files = list(fuzzilli_path.rglob(\"*.js\"))\n",
    "\n",
    "# # die_path = Path(\"../corpus/interesting/die-2\")\n",
    "# # files = list(die_path.rglob(\"*\"))\n",
    "\n",
    "# for file in (bar := tqdm.tqdm(files)):\n",
    "#     if file.with_suffix(\".exec\").exists():\n",
    "#         exec_data = pickle.load(open(file.with_suffix(\".exec\"), \"rb\"))\n",
    "#     else:\n",
    "#       with open(file, \"r\") as f:\n",
    "#         code = f.read()\n",
    "#         exec_data = engine.execute_text(code)\n",
    "\n",
    "#       with open(file.with_suffix(\".exec\"), \"wb\") as f:\n",
    "#           pickle.dump(exec_data, f)\n",
    "\n",
    "#     if exec_data is None:\n",
    "#         print(f\"File {file} failed to execute\")\n",
    "#         continue\n",
    "\n",
    "#     total_coverage = total_coverage | exec_data.coverage\n",
    "#     bar.set_postfix({\"coverage\": total_coverage.coverage()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(total_coverage) #16.19981\n",
    "# print(data[\"total_coverage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume = \"2023-06-20T06:37:.270395_baseline\"\n",
    "\n",
    "# total_coverage = data[\"total_coverage\"]\n",
    "# subtrees = data[\"subtrees\"]\n",
    "# new_corpus = data[\"corpus\"]\n",
    "\n",
    "# corpus_path = Path(\"../corpus/interesting\") / resume\n",
    "# corpus_files = list(corpus_path.rglob(\"*.js\"))\n",
    "\n",
    "# for file in tqdm.tqdm(corpus_files):\n",
    "#     if file.with_suffix(\".exec\").exists():\n",
    "#         exec_data = pickle.load(open(file.with_suffix(\".exec\"), \"rb\"))\n",
    "#     else:\n",
    "#       with open(file, \"r\") as f:\n",
    "#         code = f.read()\n",
    "#         exec_data = engine.execute_text(code)\n",
    "#         with open(file.with_suffix(\".exec\"), \"wb\") as f:\n",
    "#             pickle.dump(exec_data, f)\n",
    "\n",
    "#     if exec_data is None:\n",
    "#         print(f\"File {file} failed to execute\")\n",
    "#         continue\n",
    "\n",
    "#     with open(file.with_suffix(\".ps\"), \"rb\") as f:\n",
    "#         program_state = pickle.load(f)\n",
    "\n",
    "#     total_coverage = exec_data.coverage| total_coverage\n",
    "#     new_corpus.append(program_state)\n",
    "\n",
    "# print(total_coverage)\n",
    "\n",
    "# with open(f\"../data/js-rl/corpus-8.5-{resume}.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\n",
    "#         \"corpus\": new_corpus,\n",
    "#         \"subtrees\": subtrees,\n",
    "#         \"total_coverage\": total_coverage,\n",
    "#     }, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "js-rl-vfj9GiAe-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
